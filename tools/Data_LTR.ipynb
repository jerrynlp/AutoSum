{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Data Set for LTR\n",
    "\n",
    "## Phrases from Summaries\n",
    "## Phrases from Stroies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Phrase:\n",
    "    \"\"\"Information of a phrase\"\"\"\n",
    "    def __init__(self, word, word_before, word_after, chapter_id, sentence_id, negation):\n",
    "        self.negation = negation\n",
    "        self.word = word\n",
    "        self.word_before = word_before\n",
    "        self.word_after = word_after\n",
    "        self.chapter_id = chapter_id\n",
    "        self.sentence_id = sentence_id\n",
    "        self.count = 0\n",
    "        self.weight = 0\n",
    "    def add_info(self):\n",
    "        self.count += 1\n",
    "    def output(self):\n",
    "        return str(self.weight) + \"\\t\" + str(self.chapter_id) + \"\\t\" + str(self.sentence_id) + \"\\t\" + self.word \\\n",
    "    + \"\\t\" + self.word_before + \"\\t\" + self.word_after + \"\\t\" + str(self.count)\n",
    "class PhraseSet:\n",
    "    \"\"\"Set to manage phrases\"\"\"\n",
    "    def __init__(self, story_id, character_id):\n",
    "        self.phrases = {}\n",
    "        self.story_id = story_id\n",
    "        self.character_id = character_id\n",
    "    def add(self, word, chapter_id, sentence_id, negation, word_before, word_after):\n",
    "        if not word in self.phrases:\n",
    "            self.phrases[word] = Phrase(word, word_before, word_after, chapter_id, sentence_id, negation)\n",
    "        self.phrases[word].add_info()\n",
    "    def clear(self):\n",
    "        self.phrases = {}\n",
    "    def sort(self):\n",
    "        return sorted(self.phrases.items(), lambda x, y: cmp(x[1].weight, y[1].weight), reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850\t7\t0\t45\t2736\tbusy too\tbe\t,\t6\n",
      "1850\t7\t0\t22\t1459\tso trustful\tbe\tand\t1\n",
      "1850\t7\t0\t48\t2882\tmine\tbe\t.\t1\n",
      "1850\t7\t0\t47\t2778\tonly one\tthe\twho\t2\n",
      "1850\t7\t0\t47\t2800\tlittle confident too\ta\t,\t2\n",
      "1850\t7\t0\t37\t2304\tfine\tbe\t.\t1\n",
      "2300\t2\t0\t13\t1757\tout cold\tbe\t.\t1\n",
      "2300\t2\t0\t11\t1271\tright\tbe\t;\t1\n",
      "2300\t2\t0\t10\t922\tday-dreaming\tbe\t,\t5\n",
      "2300\t2\t0\t11\t1282\tunfazed\tremain\t.\t2\n",
      "2300\t2\t0\t12\t1380\tREALLY powerful\tbe\tbut\t1\n",
      "2300\t2\t0\t14\t1908\tmost experienced\tthe\t,\t2\n",
      "2300\t2\t0\t1\t11\tsmall\tbe\tcompare\t3\n",
      "2300\t2\t0\t14\t1907\ttrue leader\tthe\t.\t1\n",
      "2300\t2\t0\t11\t1162\tmore\tlot\tthan\t1\n",
      "2300\t13\t0\t10\t924\told fart\ta\t.\t3\n",
      "2540\t0\t0\t9\t683\tex-boyfriend\tmy\t.\t1\n",
      "2540\t0\t0\t8\t569\tfirst love\tmy\t.\t1\n",
      "2540\t0\t0\t11\t885\tso muscular\tbe\t.\t2\n"
     ]
    }
   ],
   "source": [
    "import Syntax as sx\n",
    "BOOK_ID = 0\n",
    "CHAPTER_ID = 1\n",
    "SENTENCE_ID = 2\n",
    "CHARACTER_ID = 15\n",
    "def sim(phrase1, phrase2):\n",
    "    return 0\n",
    "def cal_similarity(summarySet, storySet):\n",
    "    for phrase1 in storySet.phrases.values():\n",
    "        max_sim = 0\n",
    "        for phrase2 in summarySet.phrases.values():\n",
    "            similarity = sim(phrase1, phrase2)\n",
    "            if max_sim < similarity:\n",
    "                max_sim = similarity\n",
    "        phrase1.weight = max_sim\n",
    "def process(summary, story, story_id):\n",
    "    #phrases and characters in summary\n",
    "    characters = {}\n",
    "    pos = 0\n",
    "    for sentence in summary:\n",
    "        for token in sentence:\n",
    "            cid = int(token[CHARACTER_ID])\n",
    "            if cid >= 0:\n",
    "                if not cid in characters:\n",
    "                    characters[cid] = [[], [], PhraseSet(story_id, cid), PhraseSet(story_id, cid)]\n",
    "                characters[cid][0].append(pos)\n",
    "        pos += 1\n",
    "    for cid in characters.keys():\n",
    "        for sid in characters[cid][0]:\n",
    "            sentence = summary[sid]\n",
    "            syn = sx.SyntaxTree()\n",
    "            syn.creat(sentence)\n",
    "            labels = syn.extract_label_with_info(cid)\n",
    "            for label in labels:\n",
    "                characters[cid][2].add(label[1], syn.chapterID, syn.sentenceID, label[0], label[2], label[3])\n",
    "    for sentence in story:\n",
    "        for token in sentence:\n",
    "            cid = int(token[CHARACTER_ID])\n",
    "            if cid in characters:\n",
    "                syn = sx.SyntaxTree()\n",
    "                syn.creat(sentence)\n",
    "                labels = syn.extract_label_with_info(cid)\n",
    "                for label in labels:\n",
    "                    characters[cid][3].add(label[1], syn.chapterID, syn.sentenceID, label[0], label[2], label[3])\n",
    "    for cid in characters:\n",
    "        cal_similarity(characters[cid][2], characters[cid][3])\n",
    "        sorted_phrases = characters[cid][3].sort()\n",
    "        for phrase in characters[cid][2].phrases:\n",
    "            print str(characters[cid][2].story_id) + \"\\t\" + str(characters[cid][2].character_id) \\\n",
    "            + \"\\t\" + phrase.output()\n",
    "        for phrase in sorted_phrases:\n",
    "            print str(characters[cid][3].story_id) + \"\\t\" + str(characters[cid][3].character_id) \\\n",
    "            + \"\\t\" + phrase[1].output()\n",
    "    return 0\n",
    "\n",
    "token_file = open(\"../../2.part.tokens.sample\", 'rb')\n",
    "story_id = -1\n",
    "chapter_id = -1\n",
    "sentence_id = -1\n",
    "summary = []\n",
    "story = []\n",
    "sentence = []\n",
    "for line in token_file:\n",
    "    terms = line.rstrip().split('\\t')\n",
    "    if not int(terms[BOOK_ID]) == story_id:\n",
    "        #process\n",
    "        process(summary, story, story_id)\n",
    "        #new story\n",
    "        story_id = int(terms[BOOK_ID])\n",
    "        chapter_id = int(terms[CHAPTER_ID])\n",
    "        sentence_id = int(terms[SENTENCE_ID])\n",
    "        summary = []\n",
    "        story = []\n",
    "        sentence.append(terms)\n",
    "    if int(terms[CHAPTER_ID]) == chapter_id and int(terms[SENTENCE_ID]) == sentence_id:\n",
    "        sentence.append(terms)\n",
    "    else:\n",
    "        if len(sentence):\n",
    "            if chapter_id == 0:\n",
    "                summary.append(sentence)\n",
    "            else:\n",
    "                story.append(sentence)\n",
    "        chapter_id = int(terms[CHAPTER_ID])\n",
    "        sentence_id = int(terms[SENTENCE_ID])\n",
    "        sentence = []\n",
    "        sentence.append(terms)\n",
    "token_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
